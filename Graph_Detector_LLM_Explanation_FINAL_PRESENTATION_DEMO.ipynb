{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8de8bd313cf473eabb5a8d8ea4ba629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2cb18becee54bd786a24786d9a5eca6",
              "IPY_MODEL_80ab169a11824d53bb0cf4fcdc5a22b5",
              "IPY_MODEL_0615f10b23434ef9a009c8bf40faabf0"
            ],
            "layout": "IPY_MODEL_ca6d859d89b1422b94be94a1e57c0ef1"
          }
        },
        "a2cb18becee54bd786a24786d9a5eca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b369e8bb4240aeb928458a1f882fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_3465233e0c684e5e9a174669e55317c3",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "80ab169a11824d53bb0cf4fcdc5a22b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d1f232b64d442fb5ba4448c6ea880c",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fdd5aeca9cb45689792aabad094a4ce",
            "value": 7
          }
        },
        "0615f10b23434ef9a009c8bf40faabf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c04ea71709241a6b06ca5498c9771a2",
            "placeholder": "​",
            "style": "IPY_MODEL_01c94b6266324b0ebc47b94823c515d0",
            "value": " 7/7 [00:15&lt;00:00,  3.58s/it]"
          }
        },
        "ca6d859d89b1422b94be94a1e57c0ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b369e8bb4240aeb928458a1f882fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3465233e0c684e5e9a174669e55317c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2d1f232b64d442fb5ba4448c6ea880c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdd5aeca9cb45689792aabad094a4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c04ea71709241a6b06ca5498c9771a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c94b6266324b0ebc47b94823c515d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffaedd52ffeb45a1b013e149804fab06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e672e906a1d487484fea6522eedb856",
              "IPY_MODEL_f0cbc1deac7b487cbb3b944068b11769",
              "IPY_MODEL_12075c18b6764328a71712e578fedbda"
            ],
            "layout": "IPY_MODEL_bfa797f9e3be4058b79dc61db1ddd885"
          }
        },
        "5e672e906a1d487484fea6522eedb856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79a21cb551e44c19e9abfeed5011b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_7628e7d69c7b45d8987c1fb563f9a068",
            "value": "100%"
          }
        },
        "f0cbc1deac7b487cbb3b944068b11769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_badb70f3622b42f3ad8458b879cc9d45",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e77c7e135844160b4c63c599160e1d8",
            "value": 50
          }
        },
        "12075c18b6764328a71712e578fedbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf8dc9b0a9146af8f4385b1c7267f50",
            "placeholder": "​",
            "style": "IPY_MODEL_89103424a2604cf3aeed6eaaf95994f2",
            "value": " 50/50 [00:21&lt;00:00,  3.29it/s]"
          }
        },
        "bfa797f9e3be4058b79dc61db1ddd885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79a21cb551e44c19e9abfeed5011b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7628e7d69c7b45d8987c1fb563f9a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "badb70f3622b42f3ad8458b879cc9d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e77c7e135844160b4c63c599160e1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf8dc9b0a9146af8f4385b1c7267f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89103424a2604cf3aeed6eaaf95994f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1df81ee08b14e5a9af34315067d5c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeb4cb19abe543dd936c806dc527f88b",
              "IPY_MODEL_b91b8b47d46a42c79fd1c3a347326875",
              "IPY_MODEL_e1833b4ec0494b818fbf70b24a49d4f7"
            ],
            "layout": "IPY_MODEL_bdb9c906f06e4d62ae0e366ac9b0b61c"
          }
        },
        "eeb4cb19abe543dd936c806dc527f88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7489e1e4a208413580eb0214cea2c843",
            "placeholder": "​",
            "style": "IPY_MODEL_ea5a72ef45ca4426822196cf9f5a08e8",
            "value": "100%"
          }
        },
        "b91b8b47d46a42c79fd1c3a347326875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0998a7a6b6424d34a2185cd1c9d32d4d",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a171cd39d63e4f1d899491924ba5c05b",
            "value": 50
          }
        },
        "e1833b4ec0494b818fbf70b24a49d4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c0b119ab54475d9e48c662e77f9d02",
            "placeholder": "​",
            "style": "IPY_MODEL_8865b851898f49c48036769ac6618fd3",
            "value": " 50/50 [00:13&lt;00:00,  3.51it/s]"
          }
        },
        "bdb9c906f06e4d62ae0e366ac9b0b61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7489e1e4a208413580eb0214cea2c843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5a72ef45ca4426822196cf9f5a08e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0998a7a6b6424d34a2185cd1c9d32d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a171cd39d63e4f1d899491924ba5c05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2c0b119ab54475d9e48c662e77f9d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8865b851898f49c48036769ac6618fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "base_prompt = \"\"\"\n",
        "You are an expert PyTorch assistant. When given a code snippet, error message, and context, you will explain why the error occurred and suggest a fix.\n",
        "\n",
        "Example 1:\n",
        "Code:\n",
        "def unsupported_op(x):\n",
        "    print(x)\n",
        "    return x + 1\n",
        "Error:\n",
        "RuntimeError: I/O functions like 'print' are not supported in TorchScript.\n",
        "Context:\n",
        "Tracing with TorchDynamo\n",
        "Explanation:\n",
        "The 'print' function cannot be traced during graph compilation because it is a Python I/O operation.\n",
        "Suggested Fix:\n",
        "Remove the 'print' statement or replace it with a logging mechanism compatible with tracing.\n",
        "\n",
        "Example 2:\n",
        "Code:\n",
        "def dynamic_control_flow(x):\n",
        "    if x.mean() > 0.5:\n",
        "        return x * 2\n",
        "    else:\n",
        "        return x / 2\n",
        "Error:\n",
        "TypeError: cannot infer the value of 'x' because it depends on runtime data.\n",
        "Context:\n",
        "Scripting with TorchDynamo\n",
        "Explanation:\n",
        "Dynamic control flow is not supported in TorchScript because it cannot be determined statically.\n",
        "Suggested Fix:\n",
        "Replace the dynamic condition with a static equivalent using predefined thresholds.\n",
        "\n",
        "Now, analyze the following:\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "I_CnuOE1f_dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import string\n",
        "import pprint\n",
        "from itertools import permutations\n",
        "import json\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.parse\n",
        "import urllib.request\n",
        "import requests\n",
        "\n",
        "import spacy\n",
        "#from spacy_help_functions import get_entities, create_entity_pairs\n",
        "\n",
        "\n",
        "# Load pre-trained SpanBERT model\n",
        "#from spanbert import SpanBERT\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import time"
      ],
      "metadata": {
        "id": "rh0Nw_z-AaPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "# Generate response to prompt\n",
        "def get_gemini_completion(prompt, model_name, max_tokens, temperature, top_p, top_k):\n",
        "\n",
        "    # Initialize a generative model\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    # Configure the model with your desired parameters\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        max_output_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k\n",
        "    )\n",
        "\n",
        "    # Generate a response\n",
        "    response = model.generate_content(prompt, generation_config=generation_config)\n",
        "    print('waiting...')\n",
        "    time.sleep(1.8)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "def remove_punctuation(test_str):\n",
        "    # Using filter() and lambda function to filter out punctuation characters\n",
        "    result = ''.join(filter(lambda x: x.isalpha() or x.isdigit() or x.isspace(), test_str))\n",
        "    return result"
      ],
      "metadata": {
        "id": "UgEKhwh0Ayfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"Give a random Shakespeare quote\"\"\"\n",
        "\n",
        "# Feel free to modify the parameters below.\n",
        "# Documentation: https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini\n",
        "model_name = 'gemini-pro'\n",
        "max_tokens = 10000\n",
        "temperature = 0.3\n",
        "top_p = 1\n",
        "top_k = 32\n",
        "\n",
        "genai.configure(api_key='FILL IN KEY HERE')\n",
        "\n",
        "response_text = get_gemini_completion(prompt_text, model_name, max_tokens, temperature, top_p, top_k)\n",
        "print(response_text)"
      ],
      "metadata": {
        "id": "6HRbR05JA0Bg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d612f645-ca82-4b05-ecd0-32ace1a95669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "waiting...\n",
            "\"To be or not to be, that is the question.\" - Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbqyAHgfSjQW"
      },
      "outputs": [],
      "source": [
        "def graph_break_analysis(model, inputs):\n",
        "    result = \"\"\n",
        "    print(\"\\n=== Starting Graph Break Analysis ===\")\n",
        "    result += \"\\n=== Starting Graph Break Analysis ===\\n\"\n",
        "    explanation = torch._dynamo.explain(model)(**inputs)\n",
        "    graph_breaks_count = explanation.graph_break_count\n",
        "    graph_breaks_reasons = explanation.break_reasons\n",
        "\n",
        "    if graph_breaks_count == 0:\n",
        "        print(\"No graph breaks detected! Your model is fully optimized for torch.compile.\")\n",
        "        result += \"No graph breaks detected! Your model is fully optimized for torch.compile.\\n\"\n",
        "        return\n",
        "\n",
        "    print(f\"\\nTotal Graph Breaks Detected: {graph_breaks_count}\")\n",
        "    result += f\"\\nTotal Graph Breaks Detected: {graph_breaks_count}\\n\"\n",
        "\n",
        "    print(\"\\nGraph Break Reasons:\")\n",
        "    result += \"\\nGraph Break Reasons:\\n\"\n",
        "    for reason in graph_breaks_reasons:\n",
        "        # print(reason)\n",
        "        for fs in reason.user_stack:\n",
        "          detail = get_line_from_stack_frame(fs)\n",
        "          print(detail)\n",
        "          result += detail\n",
        "        print()\n",
        "        result += \"\\n\"\n",
        "        print(reason.reason)\n",
        "        result += reason.reason + \"\\n\"\n",
        "\n",
        "\n",
        "    print(\"\\n=== End of Graph Break Analysis ===\")\n",
        "    result += \"\\n=== End of Graph Break Analysis ===\"\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_line_from_stack_frame(stack_frame):\n",
        "    file_path = stack_frame.filename\n",
        "    line_number = stack_frame.lineno\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            # Read all lines from the file\n",
        "            lines = file.readlines()\n",
        "            # Return the specified line (line numbers are 1-indexed)\n",
        "            if 1 <= line_number <= len(lines):\n",
        "                return f\"Graph break happens at: {lines[line_number - 1].strip()} , File: {file_path}, in line: {line_number}\\n\"\n",
        "            else:\n",
        "                return f\"Error: Line number {line_number} is out of range. The file has {len(lines)} lines.\"\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: File '{file_path}' not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_break_analysis(model, inputs):\n",
        "    # Check for GPU availability\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        model = model.to(device)\n",
        "        # Move all tensor inputs to GPU\n",
        "        for k, v in inputs.items():\n",
        "            if torch.is_tensor(v):\n",
        "                inputs[k] = v.to(device)\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    result = \"\"\n",
        "    print(\"\\n=== Starting Graph Break Analysis ===\")\n",
        "    result += \"\\n=== Starting Graph Break Analysis ===\\n\"\n",
        "\n",
        "    # Call the explain function and store the result\n",
        "    explanation = torch._dynamo.explain(model)(**inputs)\n",
        "\n",
        "    # Access and print each property of the ExplainOutput object\n",
        "    print(\"\\n=== Graphs ===\")\n",
        "    result += \"\\n=== Graphs ===\\n\"\n",
        "    result += str(explanation.graphs) + \"\\n\"\n",
        "    print(explanation.graphs)\n",
        "\n",
        "    print(\"\\n=== Graph Count ===\")\n",
        "    result += \"\\n=== Graph Count ===\\n\"\n",
        "    result += str(explanation.graph_count) + \"\\n\"\n",
        "    print(explanation.graph_count)\n",
        "\n",
        "    print(\"\\n=== Graph Break Count ===\")\n",
        "    result += \"\\n=== Graph Break Count ===\\n\"\n",
        "    result += str(explanation.graph_break_count) + \"\\n\"\n",
        "    print(explanation.graph_break_count)\n",
        "\n",
        "    print(\"\\n=== Break Reasons ===\")\n",
        "    result += \"\\n=== Break Reasons ===\\n\"\n",
        "    for reason in explanation.break_reasons:\n",
        "        for fs in reason.user_stack:\n",
        "            detail = get_line_from_stack_frame(fs)\n",
        "            print(detail)\n",
        "            result += detail\n",
        "        print(reason.reason)\n",
        "        result += reason.reason + \"\\n\"\n",
        "\n",
        "    print(\"\\n=== Operation Count ===\")\n",
        "    result += \"\\n=== Operation Count ===\\n\"\n",
        "    result += str(explanation.op_count) + \"\\n\"\n",
        "    print(explanation.op_count)\n",
        "\n",
        "    print(\"\\n=== End of Graph Break Analysis ===\")\n",
        "    result += \"\\n=== End of Graph Break Analysis ===\"\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_line_from_stack_frame(stack_frame):\n",
        "    file_path = stack_frame.filename\n",
        "    line_number = stack_frame.lineno\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            if 1 <= line_number <= len(lines):\n",
        "                return f\"Graph break happens at: {lines[line_number - 1].strip()} , File: {file_path}, in line: {line_number}\\n\"\n",
        "            else:\n",
        "                return f\"Error: Line number {line_number} is out of range. The file has {len(lines)} lines.\"\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: File '{file_path}' not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n"
      ],
      "metadata": {
        "id": "BUfwt3rEjx7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"OFA-Sys/small-stable-diffusion-v0\")\n",
        "# pipe = torch.compile(pipe, mode=\"default\", fullgraph=True, backend=\"cudagraphs\")\n",
        "result = graph_break_analysis(pipe, {\"prompt\": \"apple\"})\n",
        "\n",
        "prompt = \"apple\"\n",
        "image = pipe(prompt).images[0]\n",
        "image.save(\"image.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b8de8bd313cf473eabb5a8d8ea4ba629",
            "a2cb18becee54bd786a24786d9a5eca6",
            "80ab169a11824d53bb0cf4fcdc5a22b5",
            "0615f10b23434ef9a009c8bf40faabf0",
            "ca6d859d89b1422b94be94a1e57c0ef1",
            "12b369e8bb4240aeb928458a1f882fe0",
            "3465233e0c684e5e9a174669e55317c3",
            "f2d1f232b64d442fb5ba4448c6ea880c",
            "5fdd5aeca9cb45689792aabad094a4ce",
            "1c04ea71709241a6b06ca5498c9771a2",
            "01c94b6266324b0ebc47b94823c515d0",
            "ffaedd52ffeb45a1b013e149804fab06",
            "5e672e906a1d487484fea6522eedb856",
            "f0cbc1deac7b487cbb3b944068b11769",
            "12075c18b6764328a71712e578fedbda",
            "bfa797f9e3be4058b79dc61db1ddd885",
            "e79a21cb551e44c19e9abfeed5011b8b",
            "7628e7d69c7b45d8987c1fb563f9a068",
            "badb70f3622b42f3ad8458b879cc9d45",
            "6e77c7e135844160b4c63c599160e1d8",
            "fdf8dc9b0a9146af8f4385b1c7267f50",
            "89103424a2604cf3aeed6eaaf95994f2",
            "f1df81ee08b14e5a9af34315067d5c6c",
            "eeb4cb19abe543dd936c806dc527f88b",
            "b91b8b47d46a42c79fd1c3a347326875",
            "e1833b4ec0494b818fbf70b24a49d4f7",
            "bdb9c906f06e4d62ae0e366ac9b0b61c",
            "7489e1e4a208413580eb0214cea2c843",
            "ea5a72ef45ca4426822196cf9f5a08e8",
            "0998a7a6b6424d34a2185cd1c9d32d4d",
            "a171cd39d63e4f1d899491924ba5c05b",
            "e2c0b119ab54475d9e48c662e77f9d02",
            "8865b851898f49c48036769ac6618fd3"
          ]
        },
        "id": "WFH0e41cSrv9",
        "outputId": "2ae94cd3-5c0c-49cb-d9a0-4e298a95b017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8de8bd313cf473eabb5a8d8ea4ba629"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--OFA-Sys--small-stable-diffusion-v0/snapshots/38e10e5e71e8fbf717a47a81e7543cd01c1a8140/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--OFA-Sys--small-stable-diffusion-v0/snapshots/38e10e5e71e8fbf717a47a81e7543cd01c1a8140/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "The config attributes {'predict_epsilon': True} were passed to DPMSolverMultistepScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n",
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--OFA-Sys--small-stable-diffusion-v0/snapshots/38e10e5e71e8fbf717a47a81e7543cd01c1a8140/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--OFA-Sys--small-stable-diffusion-v0/snapshots/38e10e5e71e8fbf717a47a81e7543cd01c1a8140/unet.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:221: FutureWarning: The configuration file of this scheduler: DPMSolverMultistepScheduler {\n",
            "  \"_class_name\": \"DPMSolverMultistepScheduler\",\n",
            "  \"_diffusers_version\": \"0.31.0\",\n",
            "  \"algorithm_type\": \"dpmsolver++\",\n",
            "  \"beta_end\": 0.012,\n",
            "  \"beta_schedule\": \"scaled_linear\",\n",
            "  \"beta_start\": 0.00085,\n",
            "  \"dynamic_thresholding_ratio\": 0.995,\n",
            "  \"euler_at_final\": false,\n",
            "  \"final_sigmas_type\": \"zero\",\n",
            "  \"lambda_min_clipped\": -Infinity,\n",
            "  \"lower_order_final\": true,\n",
            "  \"num_train_timesteps\": 1000,\n",
            "  \"predict_epsilon\": true,\n",
            "  \"prediction_type\": \"epsilon\",\n",
            "  \"rescale_betas_zero_snr\": false,\n",
            "  \"sample_max_value\": 1.0,\n",
            "  \"solver_order\": 2,\n",
            "  \"solver_type\": \"midpoint\",\n",
            "  \"steps_offset\": 0,\n",
            "  \"thresholding\": false,\n",
            "  \"timestep_spacing\": \"linspace\",\n",
            "  \"trained_betas\": null,\n",
            "  \"use_beta_sigmas\": false,\n",
            "  \"use_exponential_sigmas\": false,\n",
            "  \"use_karras_sigmas\": false,\n",
            "  \"use_lu_lambdas\": false,\n",
            "  \"variance_type\": null\n",
            "}\n",
            " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
            "  deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Graph Break Analysis ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin unicodedata.category. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.\n",
            "  torch._dynamo.utils.warn_once(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffaedd52ffeb45a1b013e149804fab06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] Graph break from `Tensor.item()`, consider setting:\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] or:\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] to include these operations in the captured graph.\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] \n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] Graph break: from user code at:\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0]   File \"/usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py\", line 985, in torch_dynamo_resume_in_index_for_timestep_at_974\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0]     step_index = index_candidates[0].item()\n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] \n",
            "W1213 05:58:19.459000 506 torch/_dynamo/variables/tensor.py:776] [21/0] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Graphs ===\n",
            "[GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule()]\n",
            "\n",
            "=== Graph Count ===\n",
            "31\n",
            "\n",
            "=== Graph Break Count ===\n",
            "30\n",
            "\n",
            "=== Break Reasons ===\n",
            "Graph break happens at: uncond_input = self.tokenizer( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 469\n",
            "\n",
            "Graph break happens at: encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3021\n",
            "\n",
            "Graph break happens at: return self.batch_encode_plus( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3109\n",
            "\n",
            "Graph break happens at: return self._batch_encode_plus( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3311\n",
            "\n",
            "Graph break happens at: batch_outputs = self._batch_prepare_for_model( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 892\n",
            "\n",
            "Graph break happens at: outputs = self.prepare_for_model( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 944\n",
            "\n",
            "Graph break happens at: total_len = len_ids + len_pair_ids + (self.num_special_tokens_to_add(pair=pair) if add_special_tokens else 0) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3663\n",
            "\n",
            "Graph break happens at: return len(self.build_inputs_with_special_tokens(token_ids_0, token_ids_1 if pair else None)) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 620\n",
            "\n",
            "Graph break happens at: bos_token = [self.bos_token_id] , File: /usr/local/lib/python3.10/dist-packages/transformers/models/clip/tokenization_clip.py, in line: 359\n",
            "\n",
            "Graph break happens at: return self.convert_tokens_to_ids(self.bos_token) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 1202\n",
            "\n",
            "Graph break happens at: return str(self._bos_token) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 1065\n",
            "\n",
            "<class 'tokenizers.AddedToken'> has a C/C++ based str method\n",
            "Graph break happens at: timesteps, num_inference_steps = retrieve_timesteps( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 972\n",
            "\n",
            "Graph break happens at: scheduler.set_timesteps(num_inference_steps, device=device, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 147\n",
            "\n",
            "Graph break happens at: last_timestep = ((self.config.num_train_timesteps - clipped_idx).numpy()).item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 361\n",
            "\n",
            "data dependent operator: aten._local_scalar_dense.default; to enable, set torch._dynamo.config.capture_scalar_outputs = True\n",
            "Graph break happens at: last_timestep = ((self.config.num_train_timesteps - clipped_idx).numpy()).item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 361\n",
            "\n",
            "data dependent operator: aten._local_scalar_dense.default; to enable, set torch._dynamo.config.capture_scalar_outputs = True\n",
            "Graph break happens at: sigmas = np.interp(timesteps, np.arange(0, len(sigmas)), sigmas) , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 409\n",
            "\n",
            "Can't find numpy function <function interp at 0x7da3051ff250> in torch._numpy.  Please file an issue to request support for this function.\n",
            "Graph break happens at: with self.progress_bar(total=num_inference_steps) as progress_bar: , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 1010\n",
            "\n",
            "Graph break happens at: return tqdm(total=total, **self._progress_bar_config) , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py, in line: 1566\n",
            "\n",
            "Graph break happens at: obj = cls.__new__(cls, *args, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/polyfills/__init__.py, in line: 144\n",
            "\n",
            "'skip function tqdm.__new__ in file /usr/local/lib/python3.10/dist-packages/tqdm/std.py'\n",
            "Graph break happens at: self._step_index = self.index_for_timestep(timestep) , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 997\n",
            "\n",
            "Graph break happens at: index_candidates = (schedule_timesteps == timestep).nonzero() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 974\n",
            "\n",
            "dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True\n",
            "Graph break happens at: index_candidates = (schedule_timesteps == timestep).nonzero() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 974\n",
            "\n",
            "dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True\n",
            "Graph break happens at: step_index = index_candidates[0].item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 985\n",
            "\n",
            "Tensor.item\n",
            "Graph break happens at: return self.numpy_to_pil(image) , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 771\n",
            "\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: return PIL.Image.fromarray(image, mode=image_mode) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 216\n",
            "\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: image = to_channel_dimension_format(image, output_data_format, ChannelDimension.FIRST) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 488\n",
            "\n",
            "Graph break happens at: target_channel_dim = ChannelDimension(channel_dim) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 86\n",
            "\n",
            "Enum variable is constructed with non constant values\n",
            "Graph break happens at: image, has_nsfw_concept = self.safety_checker( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 582\n",
            "\n",
            "Graph break happens at: return func(*args, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py, in line: 116\n",
            "\n",
            "Graph break happens at: concept_threshold = self.special_care_embeds_weights[concept_idx].item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py, in line: 70\n",
            "\n",
            "Tensor.item\n",
            "Graph break happens at: return self.numpy_to_pil(image) , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 771\n",
            "\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "\n",
            "=== Operation Count ===\n",
            "1694\n",
            "\n",
            "=== End of Graph Break Analysis ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1df81ee08b14e5a9af34315067d5c6c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"\n",
        "You are a PyTorch expert assisting in debugging graph breaks in PyTorch's `torch.compile` pipeline. Given the detailed analysis of graph breaks below, explain why each graph break occurred and suggest actionable fixes for them. Ensure the explanations are clear, and the suggestions are practical and compatible with PyTorch 2.x.\n",
        "\n",
        "### Instructions:\n",
        "1. Analyze the provided graph break analysis report.\n",
        "2. For each graph break, provide:\n",
        "   - An explanation of the root cause in simple terms.\n",
        "   - A fix or workaround to resolve the graph break.\n",
        "   - Indicate whether the fix is compatible with `torch.compile`.\n",
        "\n",
        "### Output Format:\n",
        "Provide the output in JSON format like this:\n",
        "{\n",
        "    \"graph_breaks\": [\n",
        "        {\n",
        "            \"location\": \"Line X, File: /path/to/file.py\",\n",
        "            \"cause\": \"Brief explanation of the cause.\",\n",
        "            \"fix\": \"Detailed fix or workaround.\",\n",
        "            \"compatible_with_torch_compile\": true/false\n",
        "        },\n",
        "        ...\n",
        "    ]\n",
        "}\n",
        "\n",
        "### Graph Break Analysis:\n",
        "\"\"\"\n",
        "prompt_text += result\n",
        "\n",
        "# Call the Gemini API\n",
        "response_text = get_gemini_completion(prompt_text, model_name, max_tokens, temperature, top_p, top_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5haAhvDJ2Kat",
        "outputId": "d218d10c-ac22-4440-c2c7-c6a58895c70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "waiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"\"\"Here is the output of a function that tracks graph break data from using the PyTorch compiler. Please explain the output in understandable terms. For each graph break occurrence, explain what happened, why the graph break happened, and a possible action to address it: \"\"\"\n",
        "#prompt_text = base_prompt\n",
        "prompt_text += result\n",
        "response_text = get_gemini_completion(prompt_text, model_name, max_tokens, temperature, top_p, top_k)"
      ],
      "metadata": {
        "id": "38ixiXCMFyml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2febef89-d561-4d03-8be5-2362252f2da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "waiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikEAShfVGOe0",
        "outputId": "e1d1db88-fa8b-4179-abb8-b4f12f3b74e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the output of a function that tracks graph break data from using the PyTorch compiler. Please explain the output in understandable terms. For each graph break occurrence, explain what happened, why the graph break happened, and a possible action to address it: \n",
            "=== Starting Graph Break Analysis ===\n",
            "\n",
            "=== Graphs ===\n",
            "[GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule(), GraphModule()]\n",
            "\n",
            "=== Graph Count ===\n",
            "31\n",
            "\n",
            "=== Graph Break Count ===\n",
            "30\n",
            "\n",
            "=== Break Reasons ===\n",
            "Graph break happens at: uncond_input = self.tokenizer( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 469\n",
            "Graph break happens at: encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3021\n",
            "Graph break happens at: return self.batch_encode_plus( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3109\n",
            "Graph break happens at: return self._batch_encode_plus( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3311\n",
            "Graph break happens at: batch_outputs = self._batch_prepare_for_model( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 892\n",
            "Graph break happens at: outputs = self.prepare_for_model( , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 944\n",
            "Graph break happens at: total_len = len_ids + len_pair_ids + (self.num_special_tokens_to_add(pair=pair) if add_special_tokens else 0) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 3663\n",
            "Graph break happens at: return len(self.build_inputs_with_special_tokens(token_ids_0, token_ids_1 if pair else None)) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py, in line: 620\n",
            "Graph break happens at: bos_token = [self.bos_token_id] , File: /usr/local/lib/python3.10/dist-packages/transformers/models/clip/tokenization_clip.py, in line: 359\n",
            "Graph break happens at: return self.convert_tokens_to_ids(self.bos_token) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 1202\n",
            "Graph break happens at: return str(self._bos_token) , File: /usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py, in line: 1065\n",
            "<class 'tokenizers.AddedToken'> has a C/C++ based str method\n",
            "Graph break happens at: timesteps, num_inference_steps = retrieve_timesteps( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 972\n",
            "Graph break happens at: scheduler.set_timesteps(num_inference_steps, device=device, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 147\n",
            "Graph break happens at: last_timestep = ((self.config.num_train_timesteps - clipped_idx).numpy()).item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 361\n",
            "data dependent operator: aten._local_scalar_dense.default; to enable, set torch._dynamo.config.capture_scalar_outputs = True\n",
            "Graph break happens at: last_timestep = ((self.config.num_train_timesteps - clipped_idx).numpy()).item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 361\n",
            "data dependent operator: aten._local_scalar_dense.default; to enable, set torch._dynamo.config.capture_scalar_outputs = True\n",
            "Graph break happens at: sigmas = np.interp(timesteps, np.arange(0, len(sigmas)), sigmas) , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 409\n",
            "Can't find numpy function <function interp at 0x7da3051ff250> in torch._numpy.  Please file an issue to request support for this function.\n",
            "Graph break happens at: with self.progress_bar(total=num_inference_steps) as progress_bar: , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 1010\n",
            "Graph break happens at: return tqdm(total=total, **self._progress_bar_config) , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py, in line: 1566\n",
            "Graph break happens at: obj = cls.__new__(cls, *args, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/polyfills/__init__.py, in line: 144\n",
            "'skip function tqdm.__new__ in file /usr/local/lib/python3.10/dist-packages/tqdm/std.py'\n",
            "Graph break happens at: self._step_index = self.index_for_timestep(timestep) , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 997\n",
            "Graph break happens at: index_candidates = (schedule_timesteps == timestep).nonzero() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 974\n",
            "dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True\n",
            "Graph break happens at: index_candidates = (schedule_timesteps == timestep).nonzero() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 974\n",
            "dynamic shape operator: aten.nonzero.default; to enable, set torch._dynamo.config.capture_dynamic_output_shape_ops = True\n",
            "Graph break happens at: step_index = index_candidates[0].item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/schedulers/scheduling_dpmsolver_multistep.py, in line: 985\n",
            "Tensor.item\n",
            "Graph break happens at: return self.numpy_to_pil(image) , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 771\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: return PIL.Image.fromarray(image, mode=image_mode) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 216\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "Graph break happens at: image = to_channel_dimension_format(image, output_data_format, ChannelDimension.FIRST) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 488\n",
            "Graph break happens at: target_channel_dim = ChannelDimension(channel_dim) , File: /usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py, in line: 86\n",
            "Enum variable is constructed with non constant values\n",
            "Graph break happens at: image, has_nsfw_concept = self.safety_checker( , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py, in line: 582\n",
            "Graph break happens at: return func(*args, **kwargs) , File: /usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py, in line: 116\n",
            "Graph break happens at: concept_threshold = self.special_care_embeds_weights[concept_idx].item() , File: /usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py, in line: 70\n",
            "Tensor.item\n",
            "Graph break happens at: return self.numpy_to_pil(image) , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 771\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: pil_images = [Image.fromarray(image) for image in images] , File: /usr/local/lib/python3.10/dist-packages/diffusers/image_processor.py, in line: 152\n",
            "Graph break happens at: shape = arr[\"shape\"] , File: /usr/local/lib/python3.10/dist-packages/PIL/Image.py, in line: 3305\n",
            "call_method GetAttrVariable(NumpyNdarrayVariable(), __array_interface__) __getitem__ (ConstantVariable(),) {}\n",
            "\n",
            "=== Operation Count ===\n",
            "1694\n",
            "\n",
            "=== End of Graph Break Analysis ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udfRfkqrGIxa",
        "outputId": "e6f394ea-a23c-45dc-f09b-7f54e7c9385b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Graph Break 1:**\n",
            "* **What happened:** The graph break occurs when the tokenizer is called without any arguments.\n",
            "* **Why it happened:** The tokenizer expects at least one argument, which is the text to be tokenized.\n",
            "* **Possible action:** Pass the appropriate text to the tokenizer.\n",
            "\n",
            "**Graph Break 2:**\n",
            "* **What happened:** The graph break occurs when the `_call_one` method of the tokenizer is called with the `text_pair` argument set to `None`.\n",
            "* **Why it happened:** The `_call_one` method expects the `text_pair` argument to be a string or a list of strings.\n",
            "* **Possible action:** Pass a valid value for the `text_pair` argument.\n",
            "\n",
            "**Graph Break 3:**\n",
            "* **What happened:** The graph break occurs when the `batch_encode_plus` method of the tokenizer is called with the `add_special_tokens` argument set to `False`.\n",
            "* **Why it happened:** The `batch_encode_plus` method expects the `add_special_tokens` argument to be a boolean value.\n",
            "* **Possible action:** Pass a valid value for the `add_special_tokens` argument.\n",
            "\n",
            "**Graph Break 4:**\n",
            "* **What happened:** The graph break occurs when the `_batch_prepare_for_model` method of the tokenizer is called with the `pair` argument set to `None`.\n",
            "* **Why it happened:** The `_batch_prepare_for_model` method expects the `pair` argument to be a string or a list of strings.\n",
            "* **Possible action:** Pass a valid value for the `pair` argument.\n",
            "\n",
            "**Graph Break 5:**\n",
            "* **What happened:** The graph break occurs when the `prepare_for_model` method of the tokenizer is called with the `add_special_tokens` argument set to `False`.\n",
            "* **Why it happened:** The `prepare_for_model` method expects the `add_special_tokens` argument to be a boolean value.\n",
            "* **Possible action:** Pass a valid value for the `add_special_tokens` argument.\n",
            "\n",
            "**Graph Break 6:**\n",
            "* **What happened:** The graph break occurs when the `num_special_tokens_to_add` method of the tokenizer is called with the `pair` argument set to `None`.\n",
            "* **Why it happened:** The `num_special_tokens_to_add` method expects the `pair` argument to be a string or a list of strings.\n",
            "* **Possible action:** Pass a valid value for the `pair` argument.\n",
            "\n",
            "**Graph Break 7:**\n",
            "* **What happened:** The graph break occurs when the `build_inputs_with_special_tokens` method of the tokenizer is called with the `token_ids_1` argument set to `None`.\n",
            "* **Why it happened:** The `build_inputs_with_special_tokens` method expects the `token_ids_1` argument to be a list of integers.\n",
            "* **Possible action:** Pass a valid value for the `token_ids_1` argument.\n",
            "\n",
            "**Graph Break 8:**\n",
            "* **What happened:** The graph break occurs when the `bos_token` attribute of the tokenizer is accessed.\n",
            "* **Why it happened:** The `bos_token` attribute is not defined for the tokenizer.\n",
            "* **Possible action:** Define the `bos_token` attribute for the tokenizer.\n",
            "\n",
            "**Graph Break 9:**\n",
            "* **What happened:** The graph break occurs when the `convert_tokens_to_ids` method of the tokenizer is called with the `token` argument set to the `bos_token` attribute.\n",
            "* **Why it happened:** The `convert_tokens_to_ids` method expects the `token` argument to be a string.\n",
            "* **Possible action:** Pass a valid value for the `token` argument.\n",
            "\n",
            "**Graph Break 10:**\n",
            "* **What happened:** The graph break occurs when the `str` method of the `tokenizers.AddedToken` class is called.\n",
            "* **Why it happened:** The `str` method is not defined for the `tokenizers.AddedToken` class.\n",
            "* **Possible action:** Define the `str` method for the `tokenizers.AddedToken` class.\n",
            "\n",
            "**Graph Break 11:**\n",
            "* **What happened:** The graph break occurs when the `retrieve_timesteps` function is called with the `timesteps` argument set to `None`.\n",
            "* **Why it happened:** The `retrieve_timesteps` function expects the `timesteps` argument to be a list of integers.\n",
            "* **Possible action:** Pass a valid value for the `timesteps` argument.\n",
            "\n",
            "**Graph Break 12:**\n",
            "* **What happened:** The graph break occurs when the `set_timesteps` method of the scheduler is called with the `num_inference_steps` argument set to `None`.\n",
            "* **Why it happened:** The `set_timesteps` method expects the `num_inference_steps` argument to be an integer.\n",
            "* **Possible action:** Pass a valid value for the `num_inference_steps` argument.\n",
            "\n",
            "**Graph Break 13:**\n",
            "* **What happened:** The graph break occurs when the `last_timestep` variable is accessed.\n",
            "* **Why it happened:** The `last_timestep` variable is not defined.\n",
            "* **Possible action:** Define the `last_timestep` variable.\n",
            "\n",
            "**Graph Break 14:**\n",
            "* **What happened:** The graph break occurs when the `interp` function of the `numpy` module is called with the `timesteps` argument set to `None`.\n",
            "* **Why it happened:** The `interp` function expects the `timesteps` argument to be a list of integers.\n",
            "* **Possible action:** Pass a valid value for the `timesteps` argument.\n",
            "\n",
            "**Graph Break 15:**\n",
            "* **What happened:** The graph break occurs when the `progress_bar` method of the pipeline is called with the `total` argument set to `None`.\n",
            "* **Why it happened:** The `progress_bar` method expects the `total` argument to be an integer.\n",
            "* **Possible action:** Pass a valid value for the `total` argument.\n",
            "\n",
            "**Graph Break 16:**\n",
            "* **What happened:** The graph break occurs when the `__new__` method of the `tqdm` class is called with the `total` argument set to `None`.\n",
            "* **Why it happened:** The `__new__` method expects the `total` argument to be an integer.\n",
            "* **Possible action:** Pass a valid value for the `total` argument.\n",
            "\n",
            "**Graph Break 17:**\n",
            "* **What happened:** The graph break occurs when the `index_for_timestep` method of the scheduler is called with the `timestep` argument set to `None`.\n",
            "* **Why it happened:** The `index_for_timestep` method expects the `timestep` argument to be an integer.\n",
            "* **Possible action:** Pass a valid value for the `timestep` argument.\n",
            "\n",
            "**Graph Break 18:**\n",
            "* **What happened:** The graph break occurs when the `nonzero` method of the `torch` module is called with the `timestep` argument set to `None`.\n",
            "* **Why it happened:** The `nonzero` method expects the `timestep` argument to be a tensor.\n",
            "* **Possible action:** Pass a valid value for the `timestep` argument.\n",
            "\n",
            "**Graph Break 19:**\n",
            "* **What happened:** The graph break occurs when the `item` method of the `Tensor` class is called.\n",
            "* **Why it happened:** The `item` method is not defined for the `Tensor` class.\n",
            "* **Possible action:** Define the `item` method for the `Tensor` class.\n",
            "\n",
            "**Graph Break 20:**\n",
            "* **What happened:** The graph break occurs when the `numpy_to_pil` method of the image processor is called with the `image` argument set to `None`.\n",
            "* **Why it happened:** The `numpy_to_pil` method expects the `image` argument to be a numpy array.\n",
            "* **Possible action:** Pass a valid value for the `image` argument.\n",
            "\n",
            "**Graph Break 21:**\n",
            "* **What happened:** The graph break occurs when the `fromarray` method of the `Image` class is called with the `image` argument set to `None`.\n",
            "* **Why it happened:** The `fromarray` method expects the `image` argument to be a numpy array.\n",
            "* **Possible action:** Pass a valid value for the `image` argument.\n",
            "\n",
            "**Graph Break 22:**\n",
            "* **What happened:** The graph break occurs when the `shape` attribute of the `arr` variable is accessed.\n",
            "* **Why it happened:** The `shape` attribute is not defined for the `arr` variable.\n",
            "* **Possible action:** Define the `shape` attribute for the `arr` variable.\n",
            "\n",
            "**Graph Break 23:**\n",
            "* **What happened:** The graph break occurs when the `to_channel_dimension_format` function is called with the `image` argument set to `None`.\n",
            "* **Why it happened:** The `to_channel_dimension_format` function expects the `image` argument to be a numpy array.\n",
            "* **Possible action:** Pass a valid value for the `image` argument.\n",
            "\n",
            "**Graph Break 24:**\n",
            "* **What happened:** The graph break occurs when the `ChannelDimension` class is\n"
          ]
        }
      ]
    }
  ]
}
